%!TEX root =  cpt-rl-icml.tex
\subsection{Optimization objective} 
Suppose the r.v. $X$ in \eqref{eq:cpt-general} is a function of a $d$-dimensional parameter $\theta$. 
In this section we consider the problem 
\begin{align}
\label{eq:opt-general}
\textrm{Find ~}\theta^* = \argmax_{\theta \in \Theta} \C(X^\theta),
\end{align}
where $\Theta$ is a compact and convex subset of $\R^d$. As mentioned earlier, the above problem encompasses policy optimization in an MDP that can be discounted or average or stochastic shortest path and/or partially observed. The difference here is that we apply the CPT-functional to the return of a policy, instead of using the expected return.  

%\begin{figure}[h]
%\centering
%\tikzstyle{block} = [draw, fill=white, rectangle,
   %minimum height=3em, minimum width=6em]
%\tikzstyle{sum} = [draw, fill=white, circle, node distance=1cm]
%\tikzstyle{input} = [coordinate]
%\tikzstyle{output} = [coordinate]
%\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]
%\scalebox{0.85}{\begin{tikzpicture}[auto, node distance=2cm,>=latex']
%% We start by placing the blocks
%\node (theta) {\large$\bm{\theta_n}$};
%\node [sum, fill=blue!20,above right=0.6cm of theta, xshift=1cm] (perturb) {\large$\bm{+}$};
%\node [sum,fill=red!20, below right=0.6cm of theta, xshift=1cm] (perturb1) {\large$\bm{-}$};
%\node [above=0.5cm of perturb] (noise) {\large$\bm{\delta_n \Delta_n}$};
%\node [below=0.5cm of perturb1] (noise1) {\large$\bm{\delta_n \Delta_n}$};    
%\node [block,fill=blue!20, right=2.5cm of perturb,label=above:{\color{bleu2}\bf Prediction}, minimum height=4em,] (psim) {\makecell{\large\bf CPT-value estimate\\[1ex] \large\bf for $\bm{\theta_n+\delta_n \Delta_n}$}}; 
%\node [block,fill=red!20, right=2.5cm of perturb1] (sim) {\makecell{\large\bf CPT-value estimate\\[1ex] \large\bf for $\bm{\theta_n-\delta_n \Delta_n}$}}; 
%\node [block, fill=green!20,below right=2cm of psim,label=above:{\color{bleu2}\bf Control}, minimum height=8em, yshift=2.5cm,text width=3.2cm] (update) {\large\bf{Gradient descent }\\[2ex]\large\bf{~~~using SPSA}};
%\node [right=0.7cm of update] (thetanext) {\large$\bm{\theta_{n+1}}$};
%
%\draw [->] (perturb) -- node[above] {\textbf{Obtain}} node[below] {$\bm{m_n}$ \textbf{samples}}  (psim);
%\draw [->] (perturb1) -- node[above] {\textbf{Obtain}} node[below] {$\bm{m_n}$ \textbf{samples}}  (sim);
%\draw [->] (noise) -- (perturb);
%\draw [->] (noise1) -- (perturb1);
%\draw [->] (psim) -- %node {$\hat J^{\theta(t)+p_1(t)}(x_0)$}
%(update.150);
%\draw [->] (sim) --  %node {$\hat J^{\theta(t)+p_2(t)}(x_0)$} 
%(update.205);
%\draw [->] (update) -- (thetanext);
%\draw [->] (theta) --   (perturb);
%\draw [->] (theta) --   (perturb1);
%\end{tikzpicture}}
%\caption{Overall flow of CPT-SPSA.}
%\label{fig:algorithm-flow}
%\end{figure}

\subsection{Gradient algorithm using SPSA (CPT-SPSA)}
\label{sec:1spsa}

\subsubsection*{Gradient estimation} 
Given that we operate in a learning setting and only have biased estimates of the CPT-value from Algorithm \ref{alg:holder-est}, we require a simulation scheme to estimate $\nabla \C(X^\theta)$.  
Simultaneous perturbation methods are a general class of stochastic gradient schemes that optimize a function given only noisy sample values - see \cite{Bhatnagar13SR} for a textbook introduction. SPSA is a well-known scheme that estimates the gradient using two sample values. In our context, at any iteration $n$ of CPT-SPSA, with parameter $\theta_n$, the gradient $\nabla \C(X^{\theta_n})$ is estimated as follows: For any  $i=1,\ldots,d$,
\begin{align}
\widehat \nabla_{i} \C(X^\theta) = \dfrac{\overline \C_n^{\theta_n+\delta_n \Delta_n} - \overline \C_n^{\theta_n-\delta_n \Delta_n}}{2 \delta_n \Delta_n^{i}},\label{eq:grad-est-spsa}
\end{align}
where $\delta_n$ is a positive scalar that satisfies (A3) below, $\Delta_n = \left( \Delta_n^{1},\ldots,\Delta_n^{d}\right)\tr$, where $\{\Delta_n^{i}, i=1,\ldots,d\}$, $n=1,2,\ldots$ are i.i.d. symmetric, $\pm 1$-valued Bernoulli r.v.s, independent of $\theta_0,\ldots,\theta_n$ and $\overline \C_n^{\theta_n+\delta_n \Delta_n}$ (resp. $\overline \C_n^{\theta_n-\delta_n \Delta_n}$) denotes the CPT-value estimate that uses $m_n$ samples of the r.v. $X^{\theta_n+\delta_n \Delta_n}$ (resp. $\overline X^{\theta_n-\delta_n \Delta_n}$).
%From the asymptotic mean square analysis that we present later, it is optimal to set $\delta_n = \delta_0/n^{0.16}$.
The (asymptotic) unbiasedness of the gradient estimate is proven in Lemma \ref{lemma:1spsa-bias}.

%This idea of using two-point feedback for estimating the gradient has been employed in various settings. Machine learning applications include bandit/stochastic convex optimization - cf. 
%\cite{hazan2015online}, \cite{duchi2013optimal}. However, the idea applies to non-convex functions as well - cf. \cite{spall2005introduction}, \cite{Bhatnagar13SR}.


\subsubsection*{Update rule} We incrementally update the parameter $\theta$ in the ascent direction as follows: For $i=1,\ldots,d$,
\begin{align}
\theta^{i}_{n+1} = \Pi_{i}\left(\theta^{i}_n + \gamma_n  \widehat \nabla_{i} \C(X^{\theta_n})\right),
\label{eq:theta-update}
\end{align}
where  $\gamma_n$ is a step-size chosen to satisfy (A3) below and
$\Pi=\left(\Pi_{1},\ldots,\Pi_{d}\right)$ is an operator that ensures that the update \eqref{eq:theta-update} stays bounded within the compact and convex set $\Theta$. 
Algorithm \ref{alg:1spsa}  presents the pseudocode.  


%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algblock{PEval}{EndPEval}
\algnewcommand\algorithmicPEval{\textbf{\em CPT-value Estimation (Trajectory 1)}}
 \algnewcommand\algorithmicendPEval{}
\algrenewtext{PEval}[1]{\algorithmicPEval\ #1}
\algrenewtext{EndPEval}{\algorithmicendPEval}

\algblock{PEvalPrime}{EndPEvalPrime}
\algnewcommand\algorithmicPEvalPrime{\textbf{\em CPT-value Estimation (Trajectory 2)}}
 \algnewcommand\algorithmicendPEvalPrime{}
\algrenewtext{PEvalPrime}[1]{\algorithmicPEvalPrime\ #1}
\algrenewtext{EndPEvalPrime}{\algorithmicendPEvalPrime}

\algblock{PImp}{EndPImp}
\algnewcommand\algorithmicPImp{\textbf{\em Gradient Ascent}}
 \algnewcommand\algorithmicendPImp{}
\algrenewtext{PImp}[1]{\algorithmicPImp\ #1}
\algrenewtext{EndPImp}{\algorithmicendPImp}

\algtext*{EndPEval}
\algtext*{EndPEvalPrime}
\algtext*{EndPImp}
%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[t]
\begin{algorithmic}
    \State {\bf Input:}  initial parameter $\theta_0 \in \Theta$ where $\Theta$ is a compact and convex subset of $\R^d$, perturbation constants $\delta_n>0$, sample sizes $\{m_n\}$, step-sizes $\{\gamma_n\}$, operator $\Pi: \R^d \rightarrow \Theta$.
\For{$n = 0,1,2,\ldots$}	
	\State Generate $\{\Delta_n^i, i=1,\ldots,d\}$ using symmetric, $\pm 1$-valued Bernoulli distribution, independent of $\{\Delta_m, m=0,1,\ldots,n-1\}$.
	\PEval
	    \State Simulate $m_n$ samples using  $(\theta_n+\delta_n \Delta_n)$.
	    \State Obtain CPT-value estimate $\overline \C_n^{\theta_n+\delta_n \Delta_n}$. 
	    \EndPEval
	    \PEvalPrime
  	    \State Simulate $m_n$ samples using $(\theta_n-\delta_n \Delta_n)$.
	    \State Obtain CPT-value estimate $\overline \C_n^{\theta_n-\delta_n \Delta_n}$.
	    \EndPEvalPrime
	    \PImp
		\State Update $\theta_n$ using \eqref{eq:theta-update}.
		\EndPImp
\EndFor
\State {\bf Return} $\theta_n$.
\end{algorithmic}
\caption{Structure of CPT-SPSA algorithm.}
\label{alg:1spsa}
\end{algorithm}

 %\begin{figure}
    %\centering
     %\begin{tabular}{cc}
%\subfigure[Simulation optimization]{
%\scalebox{0.6}{\begin{tikzpicture}
%% We start by placing the blocks
%\node (theta) {$\boldsymbol{\theta}$};
%\node [block, fill=blue!20,right=0.6cm of theta,align=center] (sample) {\makecell{\textbf{Measurement}\\\textbf{ Oracle}}}; 
%\node [right=0.6cm of sample] (end) {$\boldsymbol{\mathbf{f(\theta) + \xi}}$};
%\node [ above right= 0.6cm of end] (bias) {\textbf{Zero mean}};
%\draw [->] (theta) --  (sample);
%\draw [->] (sample) -- (end);
%\path [darkgreen,->] (bias) edge [bend left] (end);
%\end{tikzpicture}}
%}
%&
%\subfigure[CPT-value optimization]{
%\scalebox{0.6}{\begin{tikzpicture}
%% We start by placing the blocks
%\node (theta) {$\boldsymbol{\theta, \epsilon}$};
%\node [block, fill=blue!20,right=0.6cm of theta,align=center] (sample) {\makecell{\textbf{CPT}\\\textbf{ Estimator}}}; 
%\node [right=0.6cm of sample] (end) {$\boldsymbol{\mathbf{\C(X^\theta) + \epsilon}}$};
%\node [ above right= 0.6cm of end] (bias) {\textbf{Controlled bias}};
%\draw [->] (theta) --  (sample);
%\draw [->] (sample) -- (end);
%\path [red,->] (bias) edge [bend left] (end);
%\end{tikzpicture}}
%}
%\end{tabular}
%\caption{Illustration of difference between classic simulation optimization and CPT-value optimiziation settings}
%\label{fig:opt-diff}
%\end{figure}

\subsubsection*{On the number of samples $m_n$ per iteration}
The CPT-value estimation scheme is biased, i.e., providing samples with parameter $\theta_n$ at instant $n$, we obtain its CPT-value estimate as $\C(X^{\theta_n}) + \epsilon_n^\theta$, with $\epsilon_n^\theta$ denoting the bias. The bias can be controlled by increasing the number of samples $m_n$ in each iteration of CPT-SPSA (see Algorithm \ref{alg:1spsa}). This is unlike many simulation optimization settings where one only sees function evaluations with zero mean noise and there is no question of deciding on $m_n$ to control the bias as we have in our setting.

To motivate the choice for $m_n$, we first rewrite the update rule \eqref{eq:theta-update} as follows:
\begin{align*}
\theta^{i}_{n+1}  = & \Pi_{i}\bigg( \theta^{i}_n +  \gamma_n \bigg( \frac{\C(X^{\theta_n +\delta_n\Delta_n}) - \C(X^{\theta_n-\delta_n\Delta_n})}{2\delta_n\Delta_n^{i}}\bigg) \\
&+ \underbrace{\frac{(\epsilon_n^{\theta_n +\delta_n\Delta_n} - \epsilon_n^{\theta_n-\delta_n\Delta_n})}{2\delta_n\Delta_n^{i}}}_{\kappa_n}\bigg).
\end{align*}
Let $\zeta_n = \sum_{l = 0}^{n} \gamma_l \kappa_{l}$. Then, a critical requirement that allows us to ignore the bias term $\zeta_n$ is the following condition (see Lemma 1 in Chapter 2 of \cite{borkar2008stochastic}): 
$$\sup_{l\ge0} \left (\zeta_{n+l} - \zeta_n \right) \rightarrow 0 \text{ as } n\rightarrow\infty.$$ 
While Theorems \ref{prop:holder-asymptotic}--\ref{prop:holder-dkw} show that the bias $\epsilon^\theta$ is bounded above, to establish convergence of the policy gradient recursion \eqref{eq:theta-update}, we increase the number of samples $m_n$ so that the bias vanishes asymptotically.  The assumption below provides a condition on the increase rate of $m_n$.

\noindent\textbf{Assumption (A3).}  The step-sizes $\gamma_n$ and the perturbation constants 
$\delta_n$ are positive $\forall n$ and satisfy
\begin{align*}
\gamma_n, \delta_n \rightarrow 0, \frac{1}{m_n^{\alpha/2}\delta_n}\rightarrow 0,  \sum_n \gamma_n=\infty \text{ and } \sum_n \frac{\gamma_n^2}{\delta_n^2}<\infty. 
\end{align*}
While the conditions on $\gamma_n$ and $\delta_n$ are standard for SPSA-based algorithms, the condition on $m_n$ is motivated by the earlier discussion. 
A simple choice that satisfies the above conditions is $\gamma_n = a_0/n$, $m_n = m_0 n^\nu$ and $\delta_n = \delta_0/{n^\gamma}$, for some $\nu, \gamma >0$ with $\gamma > \nu\alpha/2$.

\noindent\textbf{Assumption (A4).}  CPT-value $\C(X^\theta)$ is a continuously differentiable function of $\theta$, with bounded third derivative.

In a typical RL setting involving finite state action spaces, a sufficient condition for ensuring (A4) holds is to assume that the policy is continuously differentiable in $\theta$. 

The main convergence result is stated below.
\begin{theorem}
\label{thm:1spsa-conv}
Assume (A1)-(A4).
Consider the  ordinary differential equation (ODE): 
$$\dot\theta^{i}_t = \check\Pi_{i}\left(- \nabla \C(X^{\theta^{i}_t})\right), \text{ for }i=1,\dots,d,$$ 
where 
$\check\Pi_{i}(f(\theta)) := \lim\limits_{\vartheta \downarrow 0} \frac{\Pi_{i}(\theta + \vartheta f(\theta)) - \theta}{\vartheta}$, for any continuous $f(\cdot).$
 Let $\K = \{\theta^* \mid \check\Pi_{i} \left(\nabla_i \C(X^{\theta^*})\right)=0, \forall i=1,\ldots,d\}$. Then, for $\theta_n$ governed by \eqref{eq:theta-update}, we have
$$\theta_n \rightarrow \K \text{ a.s. as } n\rightarrow \infty.$$
\end{theorem}

\begin{proof}
 See Section \ref{appendix:1spsa}.
\end{proof}

Let $\K' = \{\theta^* \mid \nabla_i \C(X^{\theta^*})=0, \forall i=1,\ldots,d\}$ denote the set of local minima of the CPT-value. If $\K'$ lies within the set $\Theta$ onto which the iterate $\theta_n$ (updated according to \eqref{eq:theta-update}) is projected, then the above theorem ensures that CPT-SPSA converges to $\K'$. However, it not possible to ensure that $\K' \subset \Theta$ in the stochastic optimization setting considered here, which implies that if $\K'$ lies outside $\Theta$, the iterate $\theta_n$ will get stuck on the boundary of $\Theta$.
%In Appendix \ref{sec:2spsa} we also give a second-order CPT-value optimization scheme based on SPSA.
%See Theorem \ref{thm:1spsa-asymp-normal} in Appendix \ref{appendix:1spsa} for a central limit theorem result, which shows that $n^{\beta/2}(\theta_n - \theta^*)$ is asymptotically normal.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Newton algorithm using SPSA (CPT-SPSA-N)}
% \label{sec:2spsa}
% \subsubsection*{Need for second-order methods}
% While stochastic gradient methods are useful in maximizing the CPT-value given biased estimates, they are sensitive to the choice of the step-size sequence $\{\gamma_n\}$.  In particular, for a step-size choice $\gamma_n = \gamma_0/n$, if $a_0$ is not chosen to be greater than $1/\left(3 \lambda_{min}(\nabla^2 \C(X^{\theta^*}))\right)$, then the optimum rate of convergence is not achieved, where $\lambda_{\min}$ denotes the minimum eigenvalue, and $\theta^*\in \K$ (see Theorem \ref{thm:1spsa-conv}). A standard approach to overcome this step-size dependency is to use iterate averaging, suggested independently by Polyak \cite{polyak1992acceleration} and Ruppert \cite{ruppert1991stochastic}. The idea is to use larger step-sizes $\gamma_n = 1/n^\varsigma$, where $\varsigma \in (1/2,1)$, for the update iteration \eqref{eq:theta-update} and average the iterates in the end, i.e., $\bar \theta_{n+1} = \frac1{n} \sum_{m=1}^n \theta_m$. However, it is well known  that iterate averaging is optimal only in an 
% asymptotic sense, while finite-time bounds show that the initial condition is not forgotten sub-exponentially fast (see 
% Theorem 2.2 in \cite{fathi2013transport}). 
% Thus, it is optimal to average iterates only 
% after a sufficient number of iterations have passed, which implies that the iterates are already close to the optimum and the updates can be stopped.
% 
% An alternative approach is to employ step-sizes of the form $\gamma_n = (a_0/n) M_n$, where $M_n$ converges to $\left(\nabla^2 \C(X^{\theta^*})\right)^{-1}$, i.e., the inverse of the Hessian of the CPT-value at the optimum $\theta^*$. Such a scheme gets rid of the step-size dependency (one can set $a_0=1$) and still obtains optimal convergence rates. This is the motivation behind having a second-order optimization scheme.
% 
% \subsubsection*{Gradient and Hessian estimation}
% We estimate the Hessian of the CPT-value function using the scheme suggested by \cite{bhatnagar2015simultaneous}. As in the first-order method, we use Rademacher random variables to simultaneously perturb all the coordinates. However, in this case, we require three system trajectories with corresponding  parameters $\theta_n+\delta_n(\Delta_n+\widehat\Delta_n)$, $\theta_n-\delta_n(\Delta_n+\widehat\Delta_n)$ and $\theta_n$, where $\{\Delta_n^i, \widehat\Delta_n^i, i=1,\ldots,d\}$ are i.i.d. Rademacher and independent of $\theta_0,\ldots,\theta_{n-1}$. Using the CPT-value estimates for the aforementioned  parameters, we estimate the Hessian and the gradient of the CPT-value function as follows: For $i,j=1,\ldots,d$, set
% \begin{align*}
% &\widehat \nabla_{i} \C(X_n^{\theta_n})=\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n)} - \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n)}}{2\delta_n \Delta_n^{i}},\\ 
% &\widehat H_n^{i,j}=\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} + \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n} - 2\overline \C_n^{\theta_n}}{\delta_n^2 \Delta_n^{i}\widehat\Delta_n^{j}}.
% \end{align*}
% Notice that the above estimates require three samples, while the second-order SPSA algorithm proposed first in \cite{spall2000adaptive} required four.
% %
% Both the gradient estimate $\widehat \nabla \C(X_n^{\theta_n}) = [\widehat \nabla_i \C(X_n^{\theta_n})], i=1,\ldots,d,$ and the Hessian estimate $\widehat{H_n} = [\widehat H_n^{i,j}], i,j=1,\ldots,d,$ can be shown to be an $O(\delta_n^2)$ term away from the true gradient $\nabla \C(X^\theta_n)$ and Hessian $\nabla^2  \C(X^\theta_n)$, respectively (see Lemmas \ref{lemma:2spsa-bias}--\ref{lemma:2spsa-grad}).
% 
% %%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
% %%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
% %\algblock{PEvalPrimeDouble}{EndPEvalPrimeDouble}
% %\algnewcommand\algorithmicPEvalPrimeDouble{\textbf{\em CPT-value Estimation (Trajectory 3)}}
%  %\algnewcommand\algorithmicendPEvalPrimeDouble{}
% %\algrenewtext{PEvalPrimeDouble}[1]{\algorithmicPEvalPrimeDouble\ #1}
% %\algrenewtext{EndPEvalPrimeDouble}{\algorithmicendPEvalPrimeDouble}
% %\algtext*{EndPEvalPrimeDouble}
% %
% %\algblock{PImpNewton}{EndPImpNewton}
% %\algnewcommand\algorithmicPImpNewton{\textbf{\em Newton step}}
%  %\algnewcommand\algorithmicendPImpNewton{}
% %\algrenewtext{PImpNewton}[1]{\algorithmicPImpNewton\ #1}
% %\algrenewtext{EndPImpNewton}{\algorithmicendPImpNewton}
% %
% %\algtext*{EndPImpNewton}
% 
% %%%%%%%%%%%%%%%%%%%
% 
% %\begin{algorithm}[t]
% %\begin{algorithmic}
% %\State {\bf Input:} 
% %initial parameter $\theta_0 \in \Theta$ where $\Theta$ is a compact and convex subset of $\R^d$, perturbation constants $\delta_n>0$, sample sizes $\{m_n\}$, step-sizes $\{\gamma_n, \xi_n\}$, operator $\Pi: \R^d \rightarrow \Theta$.
% %\For{$n = 0,1,2,\ldots$}	
% 	%\State Generate $\{\Delta_n^{i}, \widehat\Delta_n^{i}, i=1,\ldots,d\}$ using Rademacher distribution, independent of $\{\Delta_m, \widehat \Delta_m, m=0,1,\ldots,n-1\}$.
% 	%\PEval
% 	    %\State Simulate $m_n$ samples  using parameter $(\theta_n+\delta_n (\Delta_n + \hat \Delta_n))$.
% 	    %\State Obtain CPT-value estimate $\overline \C_n^{\theta_n+\delta_n (\Delta_n+\hat \Delta_n)}$.
% 	    %\EndPEval
% 	    %\PEvalPrime
%   	    %\State Simulate $m_n$ samples using parameter $(\theta_n-\delta_n (\Delta_n + \hat \Delta_n))$.
% 	    %\State Obtain CPT-value estimate $\overline \C_n^{\theta_n-\delta_n (\Delta_n+\hat\Delta_n)}$.
% 	    %\EndPEvalPrime
% 	    	    %\PEvalPrimeDouble
%   	    %\State Simulate $m_n$ samples using parameter $\theta_n$.
% 	    %\State Obtain CPT-value estimate $\overline \C_n^{\theta_n}$ using Algorithm \ref{alg:holder-est}.
% 	    %\EndPEvalPrimeDouble
% 	    %\PImpNewton
% 		%%\State Gradient estimate $\widehat \nabla_{i} \C(X^\theta_n)\quad=\quad\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} - \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n}}{2\delta_n \Delta_n^{i}}$
%         %%\State Hessian estimate $\widehat H_n\quad=\quad\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} + \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n} - 2\widehat \nabla_{i} \C(X^\theta_n)}{\delta_n^2 \Delta_n^{i}\widehat\Delta_n^j}$
% 		%\State Update the parameter and Hessian according to \eqref{eq:2spsa}--\eqref{eq:2spsa-H}.
% 		%\EndPImpNewton
% %\EndFor
% %\State {\bf Return} $\theta_n.$
% %\end{algorithmic}
% %\caption{Structure of CPT-SPSA-N algorithm.}
% %\label{alg:structure-2}
% %\end{algorithm}
% 
% \subsubsection*{Update rule}
% We update the parameter incrementally using a Newton decrement as follows: For $i=1,\ldots,d$,
% \begin{align}
% \label{eq:2spsa}
% % \theta_{n+1} =& \theta_{(1-\xi)\Theta}(\theta_n - \gamma_n \Upsilon(\overline H_n)^{-1} \widehat\nabla V^\theta_n(x^0)), \\
% \theta^{i}_{n+1} =& \Pi_{i}\left(\theta^{i}_n + \gamma_n \sum_{j=1}^{d} M_n^{i,j} \widehat \nabla_{j} \C(X^\theta_n)\right), \\
% \overline H_n = & (1-\xi_n) \overline H_{n-1} + \xi_n \widehat H_n,\label{eq:2spsa-H}
% \end{align}
% where $\xi_n$ is a step-size sequence that satisfies 
% $\sum_{n} \xi_n = \infty, \sum_n \xi_n^2 < \infty$ and $\frac{\gamma_n}{\xi_n}\rightarrow 0$ as $n\rightarrow \infty$. These conditions on $\xi_n$ ensure that the updates to $\overline H_n$ proceed on a timescale that is faster than that of $\theta_n$ in \eqref{eq:2spsa} - see Chapter 6 of \cite{borkar2008stochastic}.
% Further, $\Pi$ is a projection operator as in CPT-SPSA and  $M_n = [M_n^{i,j}] = \Upsilon(\overline H_n)^{-1}$.
% % ,  $\widehat\nabla V^\theta_n(x^0)$ is an estimate of the gradient of the CPT-value function and $\widehat H_n$ and $\overline H_n$ denote the Hessian estimate and its smooth counterpart, respectively. 
% Notice that we invert $\overline H_n$ in each iteration, and to ensure that this inversion is feasible (so that the $\theta$-recursion descends), we project $\overline H_n$ onto the set of positive definite matrices using the operator $\Upsilon$. The operator has to be such that asymptotically $\Upsilon(\overline H_n)$ should be the same as $\overline H_n$ (since the latter would converge to the true Hessian), while ensuring inversion is feasible in the initial iterations.  The assumption below makes these requirements precise.\\[1ex]
% \textbf{Assumption (A5).}  For any $\{A_n\}$ and $\{B_n\}$,
% ${\displaystyle \lim_{n\rightarrow \infty} \left\| A_n-B_n \right\|}= 0 \Rightarrow {\displaystyle \lim_{n\rightarrow \infty} \parallel \Upsilon(A_n)- \Upsilon(B_n) \parallel}= 0$. Further, for any $\{C_n\}$  with
% ${\displaystyle \sup_n \parallel C_n\parallel}<\infty$,
% ${\displaystyle \sup_n \left(\parallel \Upsilon(C_n)\parallel + \parallel \{\Upsilon(C_n)\}^{-1} \parallel\right) < \infty}$.
% \\[0.5ex]
% %A simple way to define $\Upsilon(\overline H_n)$ is to first perform an eigen-decomposition of $\overline H_n$, followed by projecting all the eigen values onto the positive side (see \cite{gill1981practical} for a similar operator). 
% A simple way to ensure the above is to have $\Upsilon(\cdot)$ as a diagonal matrix and then add a positive scalar $\delta_n$ to the diagonal elements so as to ensure invertibility  - see \cite{gill1981practical}, \cite{spall2000adaptive} for a similar operator.
% %- this choice satisfies requirement (ii) in Theorem \ref{thm:2spsa} presented below.
% 
% %We next specify how the gradient $\widehat \nabla_i V^\theta_n(x^0)$ and Hessian $\widehat H_n$ estimates are obtained using SPSA.
% %Algorithm \ref{alg:structure-2} presents the pseudocode.  
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The main convergence result is stated below.
% \begin{theorem}
% \label{thm:2spsa}
% Assume (A1)-(A5). 
% Consider the ODE: 
% $$
% \dot\theta^{i}_t = \check\Pi_{i}\left( - \Upsilon(\nabla^2 \C(X^{\theta_t}))^{-1} \nabla \C(X^{\theta^{i}_t}) \right), \text { for }i=1,\dots,d,$$
% where 
% $\bar\Pi_{i}$ is as defined in Theorem \ref{thm:1spsa-conv}. Let $\K = \{\theta \in \Theta \mid
% \nabla \C(X^{\theta^{i}})  \check\Pi_{i}\left(-\Upsilon(\nabla^2 \C(X^{\theta}))^{-1} \nabla \C(X^{\theta^{i}})\right)
% =0, \forall i=1,\ldots,d\}$. Then, for $\theta_n$ governed by \eqref{eq:2spsa}, 
% we have
% $$\theta_n \rightarrow \K  \text{~~ a.s. as } n\rightarrow \infty.$$ 
% \end{theorem}
% 
% \begin{proof}
% See Section \ref{sec:proofs-spsa-n}.
% \end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Model-based parameter search algorithm (CPT-MPS)}
\label{sec:mras}
In this section, we provide a gradient-free algorithm (CPT-MPS) for maximizing CPT-value, that is based on MRAS$_2$ from \cite{chang2013simulation}. We require that there exists a unique global optimum $\theta^*$ for the problem \eqref{eq:opt-general}.

% The crucial difference between CPT-MPS and MRAS$_2$ is that the latter has an expected function value objective, i.e., it aims to minimize a function by using sample observations that have zero-mean noise. On the other hand, the objective in our setting is the CPT-value, which distorts the underlying transition probabilities. The implication here is that MRAS$_2$ can estimate the expected value using sample averages, while we have to resort to integrating the empirical distribution, which results in biased estimates.


\subsubsection*{Basic algorithm}
To illustrate the main idea in the algorithm, assume we know the form of $\C(X^{\theta})$. Then, the idea is to generate a sequence of reference distributions $g_k(\theta)$ on the parameter space $\Theta$, such that it eventually concentrates on the global optimum $\theta^*$. One simple way, suggested in Chapter 4 of \cite{chang2013simulation} is
\begin{equation}
\label{eqn:naive}
g_{k}(\theta)=
\frac{\mathcal{H}(\C(X^{\theta}))g_{k-1}(\theta)}
{\int_{\Theta}\mathcal{H}(V^{\theta'}(x^0))g_{k-1}(\theta')\nu(d\theta')},
~~\forall\, \theta \in \Theta,
\end{equation}
where $\nu$ is the Lebesgue/counting measure on $\Theta$ and $\mathcal{H}$ is a strictly decreasing function. The above construction for $g_k$'s assigns more weight to policies having higher CPT-values, and it is easy to show that $g_k$ converges to a point-mass concentrated at $\theta^*$.

Next, consider a setting where one can obtain the CPT-value $\C(X^{\theta})$ (without any noise) for any parameter $\theta$. In this case, we consider a family of parameterized distributions, say $\{f(\cdot,\eta),\,\eta\in \C \}$ and incrementally update the distribution parameter $\eta$ such that it minimizes the following KL divergence:
\begin{align}
\label{eqn:kl}
\mathcal{D}(g_k,f(\cdot,\eta))&:=E_{g_k}\left[\ln \frac{g_{k}(\mathcal{R}(\Theta))}{f(\mathcal{R}(\Theta),\eta)}\right]\\
&=\int_{\Theta} \ln \frac{g_{k}(\theta)}{f(\theta,\eta)}g_{k}(\theta)\nu(d\theta), \nonumber
\end{align}
where $\mathcal{R}(\Theta)$ is a random vector taking values in the parameter space $\Theta$. 
%Through \ e intuition for the above is that we project the reference distributions $g_k$ onto the family $\{f(\cdot,\eta),\,\eta\in \C \}$.
An algorithm to optimize CPT-value in this \textit{noiseless} setting would perform the following update:
\begin{align}
 \label{eqn:interior}
\hspace{-0.5em}\eta_{n+1} \!\in\! \argmax_{\eta \in \C}
E_{\eta_n}\left[\frac{[\mathcal{H}(\C(X^{\mathcal{R}(\Theta)})]^{n}}
{f(\mathcal{R}(\Theta),\eta_{n})}
\ln f(\mathcal{R}(\Theta),\eta)\right],
\end{align}
where $E_{\eta_n}[\C(X^{\mathcal{R}(\Theta)})]=\int_{\Theta} \C(X^{\theta})f(\theta,\eta_n)\nu(d\theta).$



%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algrenewcommand\algorithmicindent{0.5em}

\algblock{Candidate}{EndCandidate}
\algnewcommand\algorithmicCandidate{\textbf{\em Candidate Policies}}
 \algnewcommand\algorithmicendCandidate{}
\algrenewtext{Candidate}[1]{\algorithmicCandidate\ #1}
\algrenewtext{EndCandidate}{\algorithmicendCandidate}
%%%%%%%%%%%%%%%%%%%
\algblock{Estimation}{EndEstimation}
\algnewcommand\algorithmicEstimation{\textbf{\em CPT-value Estimation}}
 \algnewcommand\algorithmicendEstimation{}
\algrenewtext{Estimation}[1]{\algorithmicEstimation\ #1}
\algrenewtext{EndEstimation}{\algorithmicendEstimation}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\algblock{Elite}{EndElite}
\algnewcommand\algorithmicElite{\textbf{\em Elite Sampling}}
 \algnewcommand\algorithmicendElite{}
\algrenewtext{Elite}[1]{\algorithmicElite\ #1}
\algrenewtext{EndElite}{\algorithmicendElite}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\algblock{Thresholding}{EndThresholding}
\algnewcommand\algorithmicThresholding{\textbf{\em Thresholding}}
 \algnewcommand\algorithmicendThresholding{}
\algrenewtext{Thresholding}[1]{\algorithmicThresholding\ #1}
\algrenewtext{EndThresholding}{\algorithmicendThresholding}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\algblock{Update}{EndUpdate}
\algnewcommand\algorithmicUpdate{\textbf{\em Sampling Distribution Update
}}
 \algnewcommand\algorithmicendUpdate{}
\algrenewtext{Update}[1]{\algorithmicUpdate\ #1}
\algrenewtext{EndUpdate}{\algorithmicendUpdate}
%%%%%%%%%%%%%%%%%%%
\algtext*{EndCandidate}
\algtext*{EndEstimation}
\algtext*{EndElite}
\algtext*{EndThresholding}
%%%%%%%%%%%%%%%%%%%

\begin{algorithm}
\begin{algorithmic}
\State {\bf Input:}  family of distributions $\{f(\cdot,\eta)\}$, initial parameter vector $\eta_0$ s.t. $f(\theta,\eta_0)>0 ~\forall\, \theta\in \Theta$, trajectory lengths $\{m_n\}$, 
$\rho_0 \in (0,1]$, $N_0>1$,
$\varepsilon> 0$, $\varsigma>1$, $\lambda \in(0,1)$,
strictly increasing function
$\mathcal{H}\hspace*{-3pt}$.

\For{$n = 0,1,2,\ldots$}	
	\Candidate
	    \State 
	    Generate $N_n$ parameters using the mixed distribution $\widetilde f(\cdot,\eta_n)= (1-\lambda)f(\cdot,\widetilde\eta_n)+\lambda f(\cdot,\eta_0)$. 
	    \State Denote these candidate policies by $\Lambda_n=\{\theta^1_n, \ldots, \theta^{N_n}\}$.
	\EndCandidate    
	\Estimation
	    \For{$i = 1,2,\ldots,N_n$}
	      \State Simulate $m_n$ samples from the distribution of $X^{\theta^i_n}$.
	      \State Obtain CPT-value estimate $\overline \C_n^{\theta^i_n}$ using Algorithm \ref{alg:holder-est}.
	      \EndFor
	\EndEstimation
	%%%%%%%%%%%%%%%%%%%%%%%%%%55
	\Elite
	  \State Order the CPT-value estimates as $\{\overline \C_n^{\theta^{(1)}_n},\ldots,\overline \C_n^{\theta^{(N_n)}_n}\}$. 
	  \State Compute the $(1-\rho_n)$-quantile as follows: 
	  \begin{align}
\widetilde \chi_{n}(\rho_n,N_n) = \overline \C_n^{\theta^{\lceil(1-\rho_k)N_k \rceil}_n}.\label{eq:quant}
\end{align}
	\EndElite
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\Thresholding
	\If {$n=0$ or $\widetilde\chi_{n}(\rho_n,N_n)\geq \bar\chi_{n-1}+\varepsilon$}
	    \State Set $\bar \chi_{k} = \widetilde \chi_{k}(\rho_n,N_n),~\rho_{k+1} = \rho_n,~N_{k+1} = N_{k}$ and \label{step:3a}
	    \State Set $\theta^*_{n} = \theta_{1-\rho_{n}}$, where $\theta_{1-\rho_{n}}$ is the parameter that corresponds to the $(1-\rho_n)$-quantile in \eqref{eq:quant}.
	\Else
             \State find the largest $\bar \rho \in (0, \rho_n)$ such that $\widetilde\chi_{n}(\bar \rho,N_n)\geq \bar\chi_{n-1}+\varepsilon$;             
             \If {$\bar \rho$ exists} 
              \State Set $\bar \chi_{n}\! =\! \widetilde \chi_{n}(\bar \rho,N_n),~ \rho_{k+1}  \!=\! \bar \rho,~N_{n+1} \!=\! N_{n}$, 
              $\theta^*_{n} \!=\! \theta_{1- \bar \rho}$ \label{step:3b} \vspace{-3ex}
              \Else
	      \State Set $\bar \chi_{n}  \!=\! \overline \C_n^{\theta^*_{n-1}}$,$\rho_{n+1} \!=\! \rho_n$,$N_{n+1} \!=\! \lceil\varsigma N_{n}\rceil,$ 
          $\theta^*_{n} \!=\! \theta^*_{n-1}$.\label{step:3c}
	      \EndIf
         \EndIf
	\EndThresholding
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
	    \Update
		                         \begin{align*} 
\eta_{n+1} \in \argmax_{\eta \in \C}\frac{1}{N_n}\sum_{i=1}^{N_n}\frac{[\mathcal{H}(\overline \C^{\theta^i_n}]^n)}{\widetilde f(\theta,\eta_n)}
\widetilde I\big(\overline \C^{\theta^i_n},\bar \chi_{n}\big) \ln f(\theta,\eta),
                            \end{align*}
                            where $\widetilde I(z,\chi):=\left\{\begin{array}{ll}
                                                          0 & ~\mbox{if $z\leq \chi-\varepsilon$,} \\
									    (z-\chi+\varepsilon)/ \varepsilon & ~\mbox{if $\chi-\varepsilon<z<\chi$,}\\
                                                          1 & ~\mbox{if $z\geq \chi$.}
                                                          \end{array} \right.$

		\EndUpdate
\EndFor
\State {\bf Return} $\theta_n$
\end{algorithmic}
\caption{Structure of  CPT-MPS algorithm.}
\label{alg:mras}
\end{algorithm}

% \footnotetext[1]{Here $\widehat V_n^{\theta^{(i)}_n}(x^0)$ denotes the $i$th order statistic.}


Finally, we get to our setting where we obtain only  biased estimates
% \footnote{Recall that the bias is due to a finite sample run followed by estimation scheme in Algorithm \ref{alg:holder-est}. As in the case of SPSA-based algorithms, it is easy to see that the number of samples $m_n$ (in iteration $n$) should asymptotically increase to infinity, to cancel the estimation bias.} 
of the CPT-value $\C(X^{\theta})$ for any parameter $\theta$, and Algorithm \ref{alg:mras} presents the pseudocode.
As noted in \cite{chang2013simulation}, it is efficient to use only an elite portion of the candidate parameters that have been sampled in order to update the sampling distribution $f(\cdot,\eta)$. This can be achieved by using a quantile estimate of the CPT-value function corresponding to candidate policies that were estimated in a particular iteration. The intuition here is that using policies that have performed well guides the parameter search procedure towards better regions more efficiently in comparison to an alternative that uses all the candidate parameters for updating $\eta$.

 A natural question is how to compute the KL-distance \eqref{eqn:kl} in order to update the parameter. A related question is how to choose the family of distributions $f(\cdot,\theta)$, so that the update \eqref{eqn:interior} can be done efficiently. One choice is to employ the natural exponential family (NEF), since it ensures that the KL distance in \eqref{eqn:kl} can be computed analytically. %See Appendix \ref{appendix:mras} for details.

% Assuming this setup, the CPT-MPS algorithm would involve the following steps:

% \begin{STDdescription}
%  \item[Step 1 (Candidate parameters):] Generate $N_n$ parameters $\{\theta^1_n, \ldots, \theta^{N_n}_n\}$ using the distribution $f(\cdot,\eta_n)$.
% 
% \item[Step 2 (CPT-value estimation):]  Obtain CPT-value estimates $\overline C_n^{\theta^i_n}$, corresponding to the parameters $\theta^i_n, i=1,\ldots, N_n$.
% 
% \item[Step 3 (Parameter update):]
%                          \begin{equation} \label{eqn:step4}
%                            \eta_{n+1} \in \argmax_{\eta \in \C}\frac{1}{N_n}\sum_{i=1}^{N_n}\frac{[\mathcal{H}(\overline \C_n^{\theta^i_n})]^n}{ f(\theta_n^i,\eta_n)}\ln f(\theta_n^i,\eta).
%                             \end{equation}
% 
% \end{STDdescription}

                    
% A few remarks are in order.

The main convergence result is stated below.
\begin{theorem}\label{thm:mras}
%Let $\varphi>0$ be a positive constant satisfying the condition that the set $\big\{\theta:\mathcal{H}(\C(X^{\theta})\geq \frac{1}{\varphi} \big\}$ has a strictly positive Lebesgue/counting measure\index{Lebesgue measure}\index{counting measure}.
Assume (A1)-(A2). Suppose that multivariate normal densities are used for the sampling distribution, i.e., $\eta_n = (\mu_n, \Sigma_n)$, where $\mu_n$ and $\Sigma_n$ denote the mean and covariance of the normal densities.
Then, 
\begin{equation}\label{eqn:smain}
\lim_{n\rightarrow \infty}\mu_n=\theta^* \text{ and } \lim_{n\rightarrow \infty}\Sigma_n=0_{d\times d}~~a.s.
\end{equation}
\end{theorem}
\begin{proof}
 See Section \ref{appendix:mras}.
\end{proof}
