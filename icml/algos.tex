%!TEX root =  cpt-rl-icml.tex
\paragraph{Optimization objective:} 
\todoc{Is this the best place for this? How about defining policy search later, after value estimation is done?}
Suppose the r.v. $X$ in \eqref{eq:cpt-general} is a function of a $d$-dimensional parameter $\theta$. 
In this section we consider the problem 
\begin{align}
\label{eq:opt-general}
\textrm{Find ~}\theta^* = \argmax_{\theta \in \Theta} \C(X^\theta),
\end{align}
where $\Theta$ is a compact and convex subset of $\R^d$. As mentioned earlier, the above problem encompasses policy optimization in an MDP that can be discounted or average or episodic and/or partially observed. The difference here is that we apply the CPT-functional to the return of a policy, instead of the expected return.  

%\begin{figure}[h]
%\centering
%\tikzstyle{block} = [draw, fill=white, rectangle,
   %minimum height=3em, minimum width=6em]
%\tikzstyle{sum} = [draw, fill=white, circle, node distance=1cm]
%\tikzstyle{input} = [coordinate]
%\tikzstyle{output} = [coordinate]
%\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]
%\scalebox{0.85}{\begin{tikzpicture}[auto, node distance=2cm,>=latex']
%% We start by placing the blocks
%\node (theta) {\large$\bm{\theta_n}$};
%\node [sum, fill=blue!20,above right=0.6cm of theta, xshift=1cm] (perturb) {\large$\bm{+}$};
%\node [sum,fill=red!20, below right=0.6cm of theta, xshift=1cm] (perturb1) {\large$\bm{-}$};
%\node [above=0.5cm of perturb] (noise) {\large$\bm{\delta_n \Delta_n}$};
%\node [below=0.5cm of perturb1] (noise1) {\large$\bm{\delta_n \Delta_n}$};    
%\node [block,fill=blue!20, right=2.5cm of perturb,label=above:{\color{bleu2}\bf Prediction}, minimum height=4em,] (psim) {\makecell{\large\bf CPT-value estimate\\[1ex] \large\bf for $\bm{\theta_n+\delta_n \Delta_n}$}}; 
%\node [block,fill=red!20, right=2.5cm of perturb1] (sim) {\makecell{\large\bf CPT-value estimate\\[1ex] \large\bf for $\bm{\theta_n-\delta_n \Delta_n}$}}; 
%\node [block, fill=green!20,below right=2cm of psim,label=above:{\color{bleu2}\bf Control}, minimum height=8em, yshift=2.5cm,text width=3.2cm] (update) {\large\bf{Gradient descent }\\[2ex]\large\bf{~~~using SPSA}};
%\node [right=0.7cm of update] (thetanext) {\large$\bm{\theta_{n+1}}$};
%
%\draw [->] (perturb) -- node[above] {\textbf{Obtain}} node[below] {$\bm{m_n}$ \textbf{samples}}  (psim);
%\draw [->] (perturb1) -- node[above] {\textbf{Obtain}} node[below] {$\bm{m_n}$ \textbf{samples}}  (sim);
%\draw [->] (noise) -- (perturb);
%\draw [->] (noise1) -- (perturb1);
%\draw [->] (psim) -- %node {$\hat J^{\theta(t)+p_1(t)}(x_0)$}
%(update.150);
%\draw [->] (sim) --  %node {$\hat J^{\theta(t)+p_2(t)}(x_0)$} 
%(update.205);
%\draw [->] (update) -- (thetanext);
%\draw [->] (theta) --   (perturb);
%\draw [->] (theta) --   (perturb1);
%\end{tikzpicture}}
%\caption{Overall flow of CPT-SPSA-G.}
%\label{fig:algorithm-flow}
%\end{figure}

\subsection{Gradient estimation} 
Given that we operate in a learning setting and only have biased estimates of the CPT-value from Algorithm \ref{alg:holder-est}, we require a simulation scheme to estimate $\nabla \C(X^\theta)$.  
Simultaneous perturbation methods are a general class of stochastic gradient schemes that optimize a function given only noisy sample values - see \cite{Bhatnagar13SR} for a textbook introduction. SPSA is a well-known scheme that estimates the gradient using two sample values. In our context, at any iteration $n$ of CPT-SPSA-G, with parameter $\theta_n$, the gradient $\nabla \C(X^{\theta_n})$ is estimated as follows: For any  $i=1,\ldots,d$,
\begin{align}
\widehat \nabla_{i} \C(X^\theta) = \dfrac{\overline \C_n^{\theta_n+\delta_n \Delta_n} - \overline \C_n^{\theta_n-\delta_n \Delta_n}}{2 \delta_n \Delta_n^{i}},\label{eq:grad-est-spsa}
\end{align}
where $\delta_n$ is a positive scalar that satisfies (A3) below, $\Delta_n = \left( \Delta_n^{1},\ldots,\Delta_n^{d}\right)\tr$, where $\{\Delta_n^{i}, i=1,\ldots,d\}$, $n=1,2,\ldots$ are i.i.d. Rademacher, independent of $\theta_0,\ldots,\theta_n$ and $\overline \C_n^{\theta_n+\delta_n \Delta_n}$ (resp. $\overline \C_n^{\theta_n-\delta_n \Delta_n}$) denotes the CPT-value estimate that uses $m_n$ samples of the r.v. $X^{\theta_n+\delta_n \Delta_n}$ (resp. $\overline X^{\theta_n-\delta_n \Delta_n}$).
%From the asymptotic mean square analysis that we present later, it is optimal to set $\delta_n = \delta_0/n^{0.16}$.
The (asymptotic) unbiasedness of the gradient estimate is proven in Lemma \ref{lemma:1spsa-bias}.

%This idea of using two-point feedback for estimating the gradient has been employed in various settings. Machine learning applications include bandit/stochastic convex optimization - cf. 
%\cite{hazan2015online}, \cite{duchi2013optimal}. However, the idea applies to non-convex functions as well - cf. \cite{spall2005introduction}, \cite{Bhatnagar13SR}.


\subsection{Update rule} We incrementally update the parameter $\theta$ in the ascent direction as follows: For $i=1,\ldots,d$,
\begin{align}
\theta^{i}_{n+1} = \Gamma_{i}\left(\theta^{i}_n + \gamma_n  \widehat \nabla_{i} \C(X^{\theta_n})\right),
\label{eq:theta-update}
\end{align}
where  $\gamma_n$ is a step-size chosen to satisfy (A3) below and
$\Gamma=\left(\Gamma_{1},\ldots,\Gamma_{d}\right)$ is an operator that ensures that the update \eqref{eq:theta-update} stays bounded within a compact and convex set $\Theta$. 
Algorithm \ref{alg:1spsa}  presents the pseudocode.  


%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algblock{PEval}{EndPEval}
\algnewcommand\algorithmicPEval{\textbf{\em CPT-value Estimation (Trajectory 1)}}
 \algnewcommand\algorithmicendPEval{}
\algrenewtext{PEval}[1]{\algorithmicPEval\ #1}
\algrenewtext{EndPEval}{\algorithmicendPEval}

\algblock{PEvalPrime}{EndPEvalPrime}
\algnewcommand\algorithmicPEvalPrime{\textbf{\em CPT-value Estimation (Trajectory 2)}}
 \algnewcommand\algorithmicendPEvalPrime{}
\algrenewtext{PEvalPrime}[1]{\algorithmicPEvalPrime\ #1}
\algrenewtext{EndPEvalPrime}{\algorithmicendPEvalPrime}

\algblock{PImp}{EndPImp}
\algnewcommand\algorithmicPImp{\textbf{\em Gradient Ascent}}
 \algnewcommand\algorithmicendPImp{}
\algrenewtext{PImp}[1]{\algorithmicPImp\ #1}
\algrenewtext{EndPImp}{\algorithmicendPImp}

\algtext*{EndPEval}
\algtext*{EndPEvalPrime}
\algtext*{EndPImp}
%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[t]
\begin{algorithmic}
    \State {\bf Input:}  initial parameter $\theta_0 \in \Theta$ where $\Theta$ is a compact and convex subset of $\R^d$, perturbation constants $\delta_n>0$, sample sizes $\{m_n\}$, step-sizes $\{\gamma_n\}$, operator $\Gamma: \R^d \rightarrow \Theta$.
\For{$n = 0,1,2,\ldots$}	
	\State Generate $\{\Delta_n^i, i=1,\ldots,d\}$ using Rademacher distribution, independent of $\{\Delta_m, m=0,1,\ldots,n-1\}$.
	\PEval
	    \State Simulate $m_n$ samples using  $(\theta_n+\delta_n \Delta_n)$.
	    \State Obtain CPT-value estimate $\overline \C_n^{\theta_n+\delta_n \Delta_n}$. 
	    \EndPEval
	    \PEvalPrime
  	    \State Simulate $m_n$ samples using $(\theta_n-\delta_n \Delta_n)$.
	    \State Obtain CPT-value estimate $\overline \C_n^{\theta_n-\delta_n \Delta_n}$.
	    \EndPEvalPrime
	    \PImp
		\State Update $\theta_n$ using \eqref{eq:theta-update}.
		\EndPImp
\EndFor
\State {\bf Return} $\theta_n$.
\end{algorithmic}
\caption{Structure of CPT-SPSA-G algorithm.}
\label{alg:1spsa}
\end{algorithm}

 %\begin{figure}
    %\centering
     %\begin{tabular}{cc}
%\subfigure[Simulation optimization]{
%\scalebox{0.6}{\begin{tikzpicture}
%% We start by placing the blocks
%\node (theta) {$\boldsymbol{\theta}$};
%\node [block, fill=blue!20,right=0.6cm of theta,align=center] (sample) {\makecell{\textbf{Measurement}\\\textbf{ Oracle}}}; 
%\node [right=0.6cm of sample] (end) {$\boldsymbol{\mathbf{f(\theta) + \xi}}$};
%\node [ above right= 0.6cm of end] (bias) {\textbf{Zero mean}};
%\draw [->] (theta) --  (sample);
%\draw [->] (sample) -- (end);
%\path [darkgreen,->] (bias) edge [bend left] (end);
%\end{tikzpicture}}
%}
%&
%\subfigure[CPT-value optimization]{
%\scalebox{0.6}{\begin{tikzpicture}
%% We start by placing the blocks
%\node (theta) {$\boldsymbol{\theta, \epsilon}$};
%\node [block, fill=blue!20,right=0.6cm of theta,align=center] (sample) {\makecell{\textbf{CPT}\\\textbf{ Estimator}}}; 
%\node [right=0.6cm of sample] (end) {$\boldsymbol{\mathbf{\C(X^\theta) + \epsilon}}$};
%\node [ above right= 0.6cm of end] (bias) {\textbf{Controlled bias}};
%\draw [->] (theta) --  (sample);
%\draw [->] (sample) -- (end);
%\path [red,->] (bias) edge [bend left] (end);
%\end{tikzpicture}}
%}
%\end{tabular}
%\caption{Illustration of difference between classic simulation optimization and CPT-value optimiziation settings}
%\label{fig:opt-diff}
%\end{figure}

\paragraph{On the number of samples $m_n$ per iteration:}
The CPT-value estimation scheme is biased, i.e., providing samples with parameter $\theta_n$ at instant $n$, we obtain its CPT-value estimate as $\C(X^{\theta_n}) + \epsilon_n^\theta$, with $\epsilon_n^\theta$ denoting the bias. The bias can be controlled by increasing the number of samples $m_n$ in each iteration of CPT-SPSA (see Algorithm \ref{alg:1spsa}). This is unlike classic simulation optimization settings where one only sees function evaluations with zero mean noise and there is no question of deciding on $m_n$ to control the bias as we have in our setting.

To motivate the choice for $m_n$, we first rewrite the update rule \eqref{eq:theta-update} as follows:
\begin{align*}
\theta^{i}_{n+1}  = & \Gamma_{i}\bigg( \theta^{i}_n +  \gamma_n \bigg( \frac{\C(X^{\theta_n +\delta_n\Delta_n}) - \C(X^{\theta_n-\delta_n\Delta_n})}{2\delta_n\Delta_n^{i}}\bigg) \\
&+ \underbrace{\frac{(\epsilon_n^{\theta_n +\delta_n\Delta_n} - \epsilon_n^{\theta_n-\delta_n\Delta_n})}{2\delta_n\Delta_n^{i}}}_{\kappa_n}\bigg).
\end{align*}
Let $\zeta_n = \sum_{l = 0}^{n} \gamma_l \kappa_{l}$. Then, a critical requirement that allows us to ignore the bias term $\zeta_n$ is the following condition (see Lemma 1 in Chapter 2 of \cite{borkar2008stochastic}): 
$$\sup_{l\ge0} \left (\zeta_{n+l} - \zeta_n \right) \rightarrow 0 \text{ as } n\rightarrow\infty.$$ 
While Theorems \ref{prop:holder-asymptotic}--\ref{prop:holder-dkw} show that the bias $\epsilon^\theta$ is bounded above, to establish convergence of the policy gradient recursion \eqref{eq:theta-update}, we increase the number of samples $m_n$ so that the bias vanishes asymptotically.  The assumption below provides a condition on the increase rate of $m_n$.

\noindent\textbf{Assumption (A3).}  The step-sizes $\gamma_n$ and the perturbation constants 
$\delta_n$ are positive $\forall n$ and satisfy
\begin{align*}
\gamma_n, \delta_n \rightarrow 0, \frac{1}{m_n^{\alpha/2}\delta_n}\rightarrow 0,  \sum_n \gamma_n=\infty \text{ and } \sum_n \frac{\gamma_n^2}{\delta_n^2}<\infty. 
\end{align*}
While the conditions on $\gamma_n$ and $\delta_n$ are standard for SPSA-based algorithms, the condition on $m_n$ is motivated by the earlier discussion. 
A simple choice that satisfies the above conditions is $\gamma_n = a_0/n$, $m_n = m_0 n^\nu$ and $\delta_n = \delta_0/{n^\gamma}$, for some $\nu, \gamma >0$ with $\gamma > \nu\alpha/2$.

\subsection{Convergence result\protect\footnote{The detailed proof is available in \cite{Pracheng2015cpt}.}}
\begin{theorem}
\label{thm:1spsa-conv}
Assume (A1)-(A3) and also that $\C(X^\theta)$ is a continuously differentiable function of $\theta$, for any $\theta \in \Theta$\footnote{In a typical RL setting, it is sufficient to assume that the policy is continuously differentiable in $\theta$.}.
Consider the  ordinary differential equation (ODE): 
$$\dot\theta^{i}_t = \check\Gamma_{i}\left(- \nabla \C(X^{\theta^{i}_t})\right), \text{ for }i=1,\dots,d,$$ 
where 
$\check\Gamma_{i}(f(\theta)) := \lim\limits_{\alpha \downarrow 0} \frac{\Gamma_{i}(\theta + \alpha f(\theta)) - \theta}{\alpha}$, for any continuous $f(\cdot).$
 Let $\K = \{\theta \mid \check\Gamma_{i} \left(\nabla_i \C(X^{\theta})\right)=0, \forall i=1,\ldots,d\}$. Then, for $\theta_n$ governed by \eqref{eq:theta-update}, we have
$$\theta_n \rightarrow \K \text{ a.s. as } n\rightarrow \infty.$$
\end{theorem}

%\begin{proof}
 %See Appendix \ref{appendix:1spsa}.
%\end{proof}
%In Appendix \ref{sec:2spsa} we also give a second-order CPT-value optimization scheme based on SPSA.
%See Theorem \ref{thm:1spsa-asymp-normal} in Appendix \ref{appendix:1spsa} for a central limit theorem result, which shows that $n^{\beta/2}(\theta_n - \theta^*)$ is asymptotically normal.  


%%%%%%%%%%
%\section{Newton algorithm for CPT-value optimization (CPT-SPSA-N)}
%\label{sec:2spsa}
%\subsection{Need for second-order methods}
%While stochastic gradient ascent methods are useful in minimizing the CPT-value given biased estimates, they are sensitive to the choice of the step-size sequence $\{\gamma_n\}$.  In particular, for a step-size choice $\gamma_n = \gamma_0/n$, if $a_0$ is not chosen to be greater than $1/3 \lambda_{min}(\nabla^2 \C(X^{\theta^*}))$, then the optimum rate of convergence is not achieved, where $\lambda_{\min}$ denotes the minimum eigenvalue, while $\theta^*\in \K$ (see Theorem \ref{thm:1spsa-conv}). A standard approach to overcome this step-size dependency is to use iterate averaging, suggested independently by Polyak \cite{polyak1992acceleration} and Ruppert \cite{ruppert1991stochastic}. The idea is to use larger step-sizes $\gamma_n = 1/n^\varsigma$, where $\varsigma \in (1/2,1)$, and then combine it with averaging of the iterates. However, it is well known  that iterate averaging is optimal only in an asymptotic sense, while finite-time bounds show that the initial condition is not forgotten sub-exponentially fast (see 
%Theorem 2.2 in \cite{fathi2013transport}). Thus, it is optimal to average iterates only 
%after a sufficient number of iterations have passed and all the iterates are very close to the optimum. However, the latter situation serves as a stopping condition in practice.
%
%An alternative approach is to employ step-sizes of the form $\gamma_n = (a_0/n) M_n$, where $M_n$ converges to $\left(\nabla^2 \C(X^{\theta^*})\right)^{-1}$, i.e., the inverse of the Hessian of the CPT-value at the optimum $\theta^*$. Such a scheme gets rid of the step-size dependency (one can set $a_0=1$) and still obtains optimal convergence rates. This is the motivation behind having a second-order optimization scheme.
%
%\subsection{Gradient and Hessian estimation}
%We estimate the Hessian of the CPT-value function using the scheme suggested by \cite{bhatnagar2015simultaneous}. As in the first-order method, we use Rademacher random variables to simultaneously perturb all the coordinates. However, in this case, we require three system trajectories with corresponding  parameters $\theta_n+\delta_n(\Delta_n+\widehat\Delta_n)$, $\theta_n-\delta_n(\Delta_n+\widehat\Delta_n)$ and $\theta_n$, where $\{\Delta_n^i, \widehat\Delta_n^i, i=1,\ldots,d\}$ are i.i.d. Rademacher and independent of $\theta_0,\ldots,\theta_n$. Using the CPT-value estimates for the aforementioned  parameters, we estimate the Hessian and the gradient of the CPT-value function as follows: For $i,j=1,\ldots,d$, set
%\begin{align*}
%&\widehat \nabla_{i} \C(X_n^{\theta_n})=\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n)} - \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n)}}{2\delta_n \Delta_n^{i}},\\ 
%&\widehat H_n^{i,j}=\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} + \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n} - 2\overline \C_n^{\theta_n}}{\delta_n^2 \Delta_n^{i}\widehat\Delta_n^{j}}.
%\end{align*}
%Notice that the above estimates require three samples, while the second-order SPSA algorithm proposed first in \cite{spall2000adaptive} required four.
%%
%Both the gradient estimate $\widehat \nabla \C(X_n^{\theta_n}) = [\widehat \nabla_i \C(X_n^{\theta_n})], i=1,\ldots,d,$ and the Hessian estimate $\widehat{H_n} = [\widehat H_n^{i,j}], i,j=1,\ldots,d,$ can be shown to be an $O(\delta_n^2)$ term away from the true gradient $\nabla \C(X^\theta_n)$ and Hessian $\nabla^2  \C(X^\theta_n)$, respectively (see Lemmas \ref{lemma:2spsa-bias}--\ref{lemma:2spsa-grad}).
%
%%%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
%%\algblock{PEvalPrimeDouble}{EndPEvalPrimeDouble}
%%\algnewcommand\algorithmicPEvalPrimeDouble{\textbf{\em CPT-value Estimation (Trajectory 3)}}
 %%\algnewcommand\algorithmicendPEvalPrimeDouble{}
%%\algrenewtext{PEvalPrimeDouble}[1]{\algorithmicPEvalPrimeDouble\ #1}
%%\algrenewtext{EndPEvalPrimeDouble}{\algorithmicendPEvalPrimeDouble}
%%\algtext*{EndPEvalPrimeDouble}
%%
%%\algblock{PImpNewton}{EndPImpNewton}
%%\algnewcommand\algorithmicPImpNewton{\textbf{\em Newton step}}
 %%\algnewcommand\algorithmicendPImpNewton{}
%%\algrenewtext{PImpNewton}[1]{\algorithmicPImpNewton\ #1}
%%\algrenewtext{EndPImpNewton}{\algorithmicendPImpNewton}
%%
%%\algtext*{EndPImpNewton}
%%
%%%%%%%%%%%%%%%%%%%%%
%%
%%\begin{algorithm}[t]
%%\begin{algorithmic}
%%\State {\bf Input:} 
%%initial parameter $\theta_0 \in \Theta$ where $\Theta$ is a compact and convex subset of $\R^d$, perturbation constants $\delta_n>0$, sample sizes $\{m_n\}$, step-sizes $\{\gamma_n, \xi_n\}$, operator $\Gamma: \R^d \rightarrow \Theta$.
%%\For{$n = 0,1,2,\ldots$}	
	%%\State Generate $\{\Delta_n^{i}, \widehat\Delta_n^{i}, i=1,\ldots,d\}$ using Rademacher distribution, independent of $\{\Delta_m, \widehat \Delta_m, m=0,1,\ldots,n-1\}$.
	%%\PEval
	    %%\State Simulate $m_n$ samples  using parameter $(\theta_n+\delta_n (\Delta_n + \hat \Delta_n))$.
	    %%\State Obtain CPT-value estimate $\overline \C_n^{\theta_n+\delta_n (\Delta_n+\hat \Delta_n)}$ using Algorithm \ref{alg:holder-est}.
	    %%\EndPEval
	    %%\PEvalPrime
  	    %%\State Simulate $m_n$ samples using parameter $(\theta_n-\delta_n (\Delta_n + \hat \Delta_n))$.
	    %%\State Obtain CPT-value estimate $\overline \C_n^{\theta_n-\delta_n (\Delta_n+\hat\Delta_n)}$ Algorithm \ref{alg:holder-est}.
	    %%\EndPEvalPrime
	    	    %%\PEvalPrimeDouble
  	    %%\State Simulate $m_n$ samples using parameter $\theta_n$.
	    %%\State Obtain CPT-value estimate $\overline \C_n^{\theta_n}$ using Algorithm \ref{alg:holder-est}.
	    %%\EndPEvalPrimeDouble
	    %%\PImpNewton
		%%%\State Gradient estimate $\widehat \nabla_{i} \C(X^\theta_n)\quad=\quad\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} - \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n}}{2\delta_n \Delta_n^{i}}$
        %%%\State Hessian estimate $\widehat H_n\quad=\quad\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} + \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n} - 2\widehat \nabla_{i} \C(X^\theta_n)}{\delta_n^2 \Delta_n^{i}\widehat\Delta_n^j}$
		%%\State Update the parameter and Hessian according to \eqref{eq:2spsa}--\eqref{eq:2spsa-H}.
		%%\EndPImpNewton
%%\EndFor
%%\State {\bf Return} $\theta_n.$
%%\end{algorithmic}
%%\caption{Structure of CPT-SPSA-N algorithm.}
%%\label{alg:structure-2}
%%\end{algorithm}
%
%\subsection{Update rule}
%We update the parameter incrementally using a Newton decrement as follows: For $i=1,\ldots,d$,
%\begin{align}
%\label{eq:2spsa}
%% \theta_{n+1} =& \theta_{(1-\xi)\Theta}(\theta_n - \gamma_n \Upsilon(\overline H_n)^{-1} \widehat\nabla V^\theta_n(x^0)), \\
%\theta^{i}_{n+1} =& \Gamma_{i}\left(\theta^{i}_n - \gamma_n \sum_{j=1}^{d} M_n^{i,j} \widehat \nabla_{j} \C(X^\theta_n)\right), \\
%\overline H_n = & (1-\xi_n) \overline H_{n-1} + \xi_n \widehat H_n,\label{eq:2spsa-H}
%\end{align}
%where $\xi_n$ is a step-size sequence that satisfies 
%$\sum_{n} \xi_n = \infty, \sum_n \xi_n^2 < \infty$ and $\frac{\gamma_n}{\xi_n}\rightarrow 0$ as $n\rightarrow \infty$. These conditions on $\xi_n$ ensure that the updates to $\overline H_n$ proceed on a timescale that is faster than that of $\theta_n$ in \eqref{eq:2spsa} - see \cite[Chapter 6]{borkar2008stochastic}.
%Further, $\Gamma$ is a projection operator as in CPT-SPSA-G and  $M_n = [M_n^{i,j}] = \Upsilon(\overline H_n)^{-1}$.
%% ,  $\widehat\nabla V^\theta_n(x^0)$ is an estimate of the gradient of the CPT-value function and $\widehat H_n$ and $\overline H_n$ denote the Hessian estimate and its smooth counterpart, respectively. 
%Notice that we invert $\overline H_n$ in each iteration, and to ensure that this inversion is feasible (so that the $\theta$-recursion descends), we project $\overline H_n$ onto the set of positive definite matrices using the operator $\Upsilon$. The operator has to be such that asymptotically $\Upsilon(\overline H_n)$ should be the same as $\overline H_n$ (since the latter would converge to the true Hessian), while ensuring inversion is feasible in the initial iterations.  The assumption below makes these requirements precise.\\[1ex]
%\textbf{Assumption (A4).}  For any $\{A_n\}$ and $\{B_n\}$,
%${\displaystyle \lim_{n\rightarrow \infty} \left\| A_n-B_n \right\|}= 0 \Rightarrow {\displaystyle \lim_{n\rightarrow \infty} \parallel \Upsilon(A_n)- \Upsilon(B_n) \parallel}= 0$. Further, for any $\{C_n\}$  with
%${\displaystyle \sup_n \parallel C_n\parallel}<\infty$,
%${\displaystyle \sup_n \left(\parallel \Upsilon(C_n)\parallel + \parallel \{\Upsilon(C_n)\}^{-1} \parallel\right) < \infty}$.
%\\[0.5ex]
%%A simple way to define $\Upsilon(\overline H_n)$ is to first perform an eigen-decomposition of $\overline H_n$, followed by projecting all the eigen values onto the positive side (see \cite{gill1981practical} for a similar operator). 
%A simple way to ensure the above is to have $\Upsilon(\cdot)$ as a diagonal matrix and then add a positive scalar $\delta_n$ to the diagonal elements so as to ensure invertibility  - see \cite{gill1981practical}, \cite{spall2000adaptive} for a similar operator.
%%- this choice satisfies requirement (ii) in Theorem \ref{thm:2spsa} presented below.
%
%%We next specify how the gradient $\widehat \nabla_i V^\theta_n(x^0)$ and Hessian $\widehat H_n$ estimates are obtained using SPSA.
%The overall flow on CPT-SPSA-N is similar to Fig. \ref{fig:algorithm-flow}, except that three system trajectories with a different perturbation sequence are used. Algorithm \ref{alg:structure-2} presents the pseudocode.  
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Convergence result}
%\begin{theorem}
%\label{thm:2spsa}
%Assume (A1)-(A4). 
%Consider the ODE: 
%$$
%\dot\theta^{i}_t = \check\Gamma_{i}\left( - \Upsilon(\nabla^2 \C(X^{\theta_t}))^{-1} \nabla \C(X^{\theta^{i}_t}) \right), \text { for }i=1,\dots,d,$$
%where 
%$\bar\Gamma_{i}$ is as defined in Theorem \ref{thm:1spsa-conv}. Let $\K = \{\theta \in \Theta \mid
%\nabla \C(X^{\theta^{i}})  \check\Gamma_{i}\left(-\Upsilon(\nabla^2 \C(X^{\theta}))^{-1} \nabla \C(X^{\theta^{i}})\right)
%=0, \forall i=1,\ldots,d\}$. Then, for $\theta_n$ governed by \eqref{eq:2spsa}, 
%we have
%$$\theta_n \rightarrow \K  \text{~~ a.s. as } n\rightarrow \infty.$$ 
%\end{theorem}
%\begin{proof}
 %See Section \ref{appendix:2spsa}.
%\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

